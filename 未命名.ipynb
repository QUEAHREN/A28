{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73ba744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T14:41:54.226780Z",
     "start_time": "2022-04-09T14:40:03.178785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/queahren/anaconda3/envs/x_pytorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:299: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Epoch[1/5], Step[100/600], Loss:0.1462\n",
      "Epoch[1/5], Step[200/600], Loss:0.0595\n",
      "Epoch[1/5], Step[300/600], Loss:0.0426\n",
      "Epoch[1/5], Step[400/600], Loss:0.0897\n",
      "Epoch[1/5], Step[500/600], Loss:0.0376\n",
      "Epoch[1/5], Step[600/600], Loss:0.0645\n",
      "Epoch[2/5], Step[100/600], Loss:0.0330\n",
      "Epoch[2/5], Step[200/600], Loss:0.0771\n",
      "Epoch[2/5], Step[300/600], Loss:0.0372\n",
      "Epoch[2/5], Step[400/600], Loss:0.1102\n",
      "Epoch[2/5], Step[500/600], Loss:0.0082\n",
      "Epoch[2/5], Step[600/600], Loss:0.0223\n",
      "Epoch[3/5], Step[100/600], Loss:0.0160\n",
      "Epoch[3/5], Step[200/600], Loss:0.0482\n",
      "Epoch[3/5], Step[300/600], Loss:0.0071\n",
      "Epoch[3/5], Step[400/600], Loss:0.0676\n",
      "Epoch[3/5], Step[500/600], Loss:0.0039\n",
      "Epoch[3/5], Step[600/600], Loss:0.0034\n",
      "Epoch[4/5], Step[100/600], Loss:0.0068\n",
      "Epoch[4/5], Step[200/600], Loss:0.0198\n",
      "Epoch[4/5], Step[300/600], Loss:0.0035\n",
      "Epoch[4/5], Step[400/600], Loss:0.0068\n",
      "Epoch[4/5], Step[500/600], Loss:0.0196\n",
      "Epoch[4/5], Step[600/600], Loss:0.0271\n",
      "Epoch[5/5], Step[100/600], Loss:0.0052\n",
      "Epoch[5/5], Step[200/600], Loss:0.0260\n",
      "Epoch[5/5], Step[300/600], Loss:0.0060\n",
      "Epoch[5/5], Step[400/600], Loss:0.0122\n",
      "Epoch[5/5], Step[500/600], Loss:0.0220\n",
      "Epoch[5/5], Step[600/600], Loss:0.0163\n",
      "Test Accuracy of the model 10000 test images:98.67%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F  # 调用F.函数\n",
    "\n",
    "# Device configuration  判断能否使用cuda加速\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5    # 循环次数\n",
    "num_classes = 10    # 分类\n",
    "batch_size = 100     # 每次投喂数据量\n",
    "learning_rate = 0.001  # 学习率\n",
    "\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='data/',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data/',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "class ResBlk(nn.Module):  # 定义Resnet Block模块\n",
    "    \"\"\"\n",
    "    resnet block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ch_in, ch_out, stride=1):  # 进入网络前先得知道传入层数和传出层数的设定\n",
    "        \"\"\"\n",
    "        :param ch_in:\n",
    "        :param ch_out:\n",
    "        \"\"\"\n",
    "        super(ResBlk, self).__init__()  # 初始化\n",
    "\n",
    "        # we add stride support for resbok, which is distinct from tutorials.\n",
    "        # 根据resnet网络结构构建2个（block）块结构 第一层卷积 卷积核大小3*3,步长为1，边缘加1\n",
    "        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=stride, padding=1)\n",
    "        # 将第一层卷积处理的信息通过BatchNorm2d\n",
    "        self.bn1 = nn.BatchNorm2d(ch_out)\n",
    "        # 第二块卷积接收第一块的输出，操作一样\n",
    "        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(ch_out)\n",
    "\n",
    "        # 确保输入维度等于输出维度\n",
    "        self.extra = nn.Sequential()  # 先建一个空的extra\n",
    "        if ch_out != ch_in:\n",
    "            # [b, ch_in, h, w] => [b, ch_out, h, w]\n",
    "            self.extra = nn.Sequential(\n",
    "                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(ch_out)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):  # 定义局部向前传播函数\n",
    "        \"\"\"\n",
    "        :param x: [b, ch, h, w]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # 对第一块卷积后的数据再经过relu操作\n",
    "        out = self.bn2(self.conv2(out))  # 第二块卷积后的数据输出\n",
    "        # short cut.\n",
    "        # extra module: [b, ch_in, h, w] => [b, ch_out, h, w]\n",
    "        # element-wise add:\n",
    "        out = self.extra(x) + out  # 将x传入extra经过2块（block）输出后与原始值进行相加\n",
    "        out = F.relu(out)  # 调用relu，这里使用F.调用\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):  # 构建resnet18层\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(  # 首先定义一个卷积层\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=3, padding=0),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        # followed 4 blocks 调用4次resnet网络结构，输出都是输入的2倍\n",
    "        # [b, 64, h, w] => [b, 128, h ,w]\n",
    "        self.blk1 = ResBlk(32, 64, stride=1)\n",
    "        # [b, 128, h, w] => [b, 256, h, w]\n",
    "        self.blk2 = ResBlk(64, 128, stride=1)\n",
    "        # # [b, 256, h, w] => [b, 512, h, w]\n",
    "        self.blk3 = ResBlk(128, 256, stride=1)\n",
    "        # # [b, 512, h, w] => [b, 1024, h, w]\n",
    "        self.blk4 = ResBlk(256, 256, stride=1)\n",
    "\n",
    "        self.outlayer = nn.Linear(256 * 1 * 1, 10)  # 最后是全连接层\n",
    "\n",
    "    def forward(self, x):  # 定义整个向前传播\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))  # 先经过第一层卷积\n",
    "\n",
    "        # [b, 64, h, w] => [b, 1024, h, w]\n",
    "        x = self.blk1(x)  # 然后通过4次resnet网络结构\n",
    "        x = self.blk2(x)\n",
    "        x = self.blk3(x)\n",
    "        x = self.blk4(x)\n",
    "\n",
    "        # print('after conv:', x.shape) #[b, 512, 2, 2]\n",
    "        # F.adaptive_avg_pool2d功能尾巴变为1,1，[b, 512, h, w] => [b, 512, 1, 1]\n",
    "        x = F.adaptive_avg_pool2d(x, [1, 1])\n",
    "        # print('after pool:', x.shape)\n",
    "        x = x.view(x.size(0), -1)  # 平铺一维值\n",
    "        x = self.outlayer(x)  # 全连接层\n",
    "\n",
    "        return x\n",
    "\n",
    "model = ResNet18().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backwad and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if(i + 1) % 100 == 0:\n",
    "            print('Epoch[{}/{}], Step[{}/{}], Loss:{:.4f}'\n",
    "                .format(epoch + 1 ,num_epochs , i + 1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model 10000 test images:{}%'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(),'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2cf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_Pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
