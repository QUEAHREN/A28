{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ae650f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T07:12:03.267430Z",
     "start_time": "2022-04-10T07:11:12.656706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "Using 8 dataloader workers every process\n",
      "using 2286 images for training, 247 images for validation.\n",
      "train epoch[1/5] loss:1.338: 100%|██████████| 143/143 [00:08<00:00, 17.25it/s]\n",
      "valid epoch[1/5]: 100%|██████████| 16/16 [00:00<00:00, 24.25it/s]\n",
      "[epoch 1] train_loss: 1.178  val_accuracy: 0.858\n",
      "train epoch[2/5] loss:0.682: 100%|██████████| 143/143 [00:08<00:00, 17.56it/s]\n",
      "valid epoch[2/5]: 100%|██████████| 16/16 [00:00<00:00, 24.54it/s]\n",
      "[epoch 2] train_loss: 0.710  val_accuracy: 0.972\n",
      "train epoch[3/5] loss:0.321: 100%|██████████| 143/143 [00:08<00:00, 17.65it/s]\n",
      "valid epoch[3/5]: 100%|██████████| 16/16 [00:00<00:00, 24.19it/s]\n",
      "[epoch 3] train_loss: 0.543  val_accuracy: 1.000\n",
      "train epoch[4/5] loss:0.497: 100%|██████████| 143/143 [00:08<00:00, 17.72it/s]\n",
      "valid epoch[4/5]: 100%|██████████| 16/16 [00:00<00:00, 24.73it/s]\n",
      "[epoch 4] train_loss: 0.456  val_accuracy: 1.000\n",
      "train epoch[5/5] loss:0.354: 100%|██████████| 143/143 [00:08<00:00, 17.79it/s]\n",
      "valid epoch[5/5]: 100%|██████████| 16/16 [00:00<00:00, 25.46it/s]\n",
      "[epoch 5] train_loss: 0.413  val_accuracy: 1.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import resnet34\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.Grayscale(1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize(256),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.Grayscale(1),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "    data_root = \"./\"\n",
    "    image_path = os.path.join(data_root, \"number_data\")  # flower data set path\n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "    train_num = len(train_dataset)\n",
    "\n",
    "    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
    "    flower_list = train_dataset.class_to_idx\n",
    "    cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    batch_size = 16\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                            transform=data_transform[\"val\"])\n",
    "    val_num = len(validate_dataset)\n",
    "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "    \n",
    "    net = resnet34()\n",
    "    # load pretrain weights\n",
    "    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "#     model_weight_path = \"./resnet34-333f7ec4.pth\"\n",
    "#     assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    \n",
    "#     net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
    "    # for param in net.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # change fc layer structure\n",
    "    in_channel = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_channel, 10)\n",
    "    net.to(device)\n",
    "\n",
    "    # define loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "    epochs = 5\n",
    "    best_acc = 0.0\n",
    "    save_path = './resNet34.pth'\n",
    "    train_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            logits = net(images.to(device))\n",
    "            loss = loss_function(logits, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                # loss = loss_function(outputs, test_labels)\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
    "                                                           epochs)\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e3c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_Pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "376.852px",
    "left": "1134px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
